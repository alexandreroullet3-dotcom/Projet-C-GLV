\documentclass[a4paper,12pt]{report}

% ============================================================
% 1. PRÉAMBULE ET CONFIGURATION
% ============================================================

% --- Encodage et Langue ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}

% --- Mise en page et Marges ---
\usepackage{geometry}
\geometry{
    top=2.5cm,
    bottom=2.5cm,
    left=2.5cm,
    right=2.5cm
}
\usepackage{setspace}
\onehalfspacing % Interligne 1.5 pour aérer et gagner en volume

% --- Mathématiques ---
\usepackage{amsmath, amssymb, amsthm, mathtools}
\usepackage{nicefrac}
\usepackage{stmaryrd} % Pour les crochets d'arrondi

% --- Graphiques et Tableaux ---
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{float}
\usepackage{multirow}
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning}

% --- Code et Algorithmes ---
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{listings}
\usepackage{xcolor}

% --- Style des titres et en-têtes ---
\usepackage{titlesec}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small \leftmark}
\fancyhead[R]{\small \textbf{Projet GLV}}
\fancyfoot[C]{\thepage}

% Configuration code C
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.96,0.96,0.96}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},    
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,          
    breaklines=true,                  
    captionpos=b,                    
    keepspaces=true,                  
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4,
    language=C,
    frame=single
}
\lstset{style=mystyle}

% --- Liens ---
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue!60!black,
    citecolor=green!60!black,
    urlcolor=blue,
    pdftitle={Rapport Technique GLV},
    pdfauthor={A. Roullet & B. Saudubray}
}

% --- Environnements ---
\theoremstyle{definition}
\newtheorem{definition}{Définition}[chapter]
\newtheorem{exemple}{Exemple}[chapter]
\newtheorem{remarque}{Remarque}[chapter]
\newtheorem{theoreme}{Théorème}[chapter]

% Configuration des titres : "hang" met le numéro et le titre sur la même ligne
\titleformat{\chapter}[hang]
  {\normalfont\huge\bfseries} % Format du texte (Gras, Huge)
  {\chaptertitlename\ \thechapter\ :} % Ce qui est écrit avant (ex: "Chapitre 1 :")
  {0.5em} % Espace entre "Chapitre 1 :" et le titre
  {}
\titlespacing*{\chapter}{0pt}{-30pt}{20pt}

% ============================================================
% 2. DOCUMENT PRINCIPAL
% ============================================================
\begin{document}

% --- Page de Garde ---
\begin{titlepage}
    \thispagestyle{fancy} 
    \centering
    \vspace*{1cm}

    \rule{\linewidth}{0.5mm} \\[0.5cm]
    { \huge \bfseries \textsc{Rapport Projet C} \\[0.4cm] 
      Analyse Exhaustive et Implémentation de la Méthode GLV sur Courbes Elliptiques \\[0.3cm] }
    \rule{\linewidth}{0.5mm}\\[1cm]
    
    \begin{minipage}{0.45\textwidth}
        \begin{flushleft} \large
            \emph{Auteurs :}\\
            Alexandre \textsc{Roullet}\\
            Bassem \textsc{Saudubray}
        \end{flushleft}
    \end{minipage}
    \begin{minipage}{0.45\textwidth}
        \begin{flushright} \large
            \emph{Supervision :}\\
            Sorina \textsc{Ionica}\\
        \end{flushright}
    \end{minipage}
    
    \vspace{2cm}
    
    \begin{center}
    \begin{minipage}{0.9\textwidth}
    \hrulefill \\
    \textbf{Résumé} \\
    Ce rapport synthétise les travaux de recherche et de développement visant à optimiser la multiplication scalaire sur les courbes elliptiques via la méthode Gallant-Lambert-Vanstone (GLV). Nous analysons en profondeur quatre familles de courbes, allant des cas classiques ($j=0$ ou $j=1728$) aux cas complexes impliquant des endomorphismes rationnels (avec $D=7$ ou $8$). Nous détaillons la théorie de la réduction de réseau (Euclide Étendu, Babai) ainsi que l'optimisation par la méthode d'entrelacement de Shamir avec fenêtrage (Windowing). L'implémentation complète en C/GMP démontre une accélération de \textbf{76\,\%} par rapport à la méthode naïve. \\
    \hrulefill
    \end{minipage}
    \end{center}
    
    \vspace{1cm}
\end{titlepage}

% --- Suite du document (PAGE 2) ---
\setcounter{page}{2} % <--- Force la table des matières à être la Page 2

% --- Table des matières ---
\tableofcontents

\newpage

% ============================================================
% CHAPITRE 1
% ============================================================
\chapter{Introduction et Contexte}

\section{La Cryptographie sur Courbes Elliptiques (ECC)}
La cryptographie asymétrique est un pilier de la sécurité numérique moderne. Depuis l'introduction de RSA, la recherche s'est orientée vers des systèmes offrant une sécurité équivalente pour des tailles de clés réduites. L'ECC (Elliptic Curve Cryptography), introduite indépendamment par Koblitz et Miller en 1985, répond à ce besoin.
Une clé ECC de 256 bits offre une résistance comparable à une clé RSA de 3072 bits, rendant l'ECC idéale pour les environnements contraints en termes de mémoire (cartes à puces, IoT) et les protocoles haute performance (Blockchain, TLS 1.3).

\section{Le Problème de la Multiplication Scalaire}
L'opération centrale de l'ECC est la \textbf{multiplication scalaire}. Étant donné un point $P$ sur une courbe $E$ et un entier $k$ (le scalaire, souvent la clé privée), on cherche à calculer :
\[ Q = kP = \underbrace{P + P + \dots + P}_{k \text{ fois}} \]
Pour un niveau de sécurité standard, $k$ est un entier de 256 bits. Une approche naïve nécessiterait $2^{256}$ additions, ce qui est impossible car bien trop coûteux en temps. Les méthodes classiques telles que Double-and-Add réduisent cette complexité à $O(\log k)$, soit environ 384 opérations de groupe (256 doublements + 128 additions).
Cependant, pour des serveurs traitant des milliers de connexions par seconde, cette opération demeure l'étape critique limitant la capacité de traitement du système.

\section{L'Approche GLV (Gallant-Lambert-Vanstone)}
En 2001, Gallant, Lambert et Vanstone ont proposé une méthode révolutionnaire. Au lieu de traiter la courbe comme un groupe quelconque, ils exploitent les propriétés géométriques de certaines courbes possédant un \textbf{endomorphisme efficace} $\phi$.
L'idée est de décomposer le scalaire $k$ en deux parties plus petites $k_1, k_2$ telles que :
\[ kP = k_1 P + k_2 \phi(P) \]
Avec $k$ de taille $n$, $k_1$ et $k_2$ sont de taille approximative $\sqrt{n}$ (soit la moitié des bits).
Cette décomposition permet de paralléliser le calcul ou d'utiliser des techniques d'entrelacement, réduisant théoriquement le nombre de doublements de moitié.

\section{Objectifs du Rapport}
Ce document a pour but de fournir une référence sur la méthode GLV. Nous aborderons :
\begin{itemize}
    \item Les fondements mathématiques rigoureux des courbes elliptiques (coordonnées Jacobiennes, corps quadratiques).
    \item L'analyse détaillée des 4 types d'endomorphismes GLV utilisés pour cette méthode (simples et complexes).
    \item Les algorithmes de décomposition basés sur les réseaux (Euclide Étendu, Babai).
    \item L'implémentation logicielle optimisée utilisant l'entrelacement de Shamir avec fenêtrage et l'analyse de performance.
\end{itemize}

\newpage

% ============================================================
% CHAPITRE 2
% ============================================================
\chapter{Fondements Mathématiques et Arithmétique}

\section{Courbes Elliptiques sur $\mathbb{F}_p$}
Nous travaillons sur un corps fini premier $\mathbb{F}_p$ avec $p > 3$. La courbe $E$ est définie par l'équation de Weierstrass courte :
\begin{equation}
    E : y^2 \equiv x^3 + ax + b \pmod p
\end{equation}
où le discriminant $\Delta = -16(4a^3 + 27b^2) \not\equiv 0$. Les points forment un groupe abélien avec le point à l'infini $\mathcal{O}$ comme élément neutre.

\subsection{Loi de composition (Formules Affines)}
L'opération d'addition est définie géométriquement par la méthode dite « corde et tangente ». Soient $P=(x_1, y_1)$ et $Q=(x_2, y_2)$ deux points de la courbe $E(\mathbb{F}_p)$.

La somme $R = P + Q = (x_3, y_3)$ est obtenue en traçant la droite passant par $P$ et $Q$ (ou la tangente si $P=Q$). Cette droite intersecte la courbe en un troisième point, dont l'opposé est le résultat $R$.

Algébriquement, on calcule d'abord la pente $\lambda$ de la droite :
\begin{equation}
    \lambda = 
    \begin{cases} 
    \frac{y_2 - y_1}{x_2 - x_1} \pmod p & \text{si } P \neq Q \text{ (Addition)} \\
    \frac{3x_1^2 + a}{2y_1} \pmod p & \text{si } P = Q \text{ (Doublement)}
    \end{cases}
\end{equation}

Les coordonnées du point résultant sont alors données par :
\begin{align}
    x_3 & = \lambda^2 - x_1 - x_2 \pmod p \\
    y_3 & = \lambda(x_1 - x_3) - y_1 \pmod p
\end{align}

\begin{remarque}
Ces formules nécessitent le calcul de l'inverse modulaire du dénominateur pour obtenir $\lambda$. Cette opération d'inversion est très coûteuse en temps de calcul (environ 20 à 80 fois le temps d'une multiplication), ce qui motive l'utilisation de systèmes de coordonnées alternatifs pour l'éviter (voir section suivante).
\end{remarque}

\section{Optimisation des Coordonnées : Le Système Jacobien}
En coordonnées affines $(x, y)$, l'addition de points nécessite le calcul d'une pente $\lambda$, impliquant une inversion modulaire ($z^{-1} \pmod p$). L'inversion est une opération très coûteuse (20 à 80 fois plus lente qu'une multiplication).

Pour éliminer ces inversions, nous utilisons les \textbf{coordonnées projectives Jacobiennes}. Un point affine $(x, y)$ est représenté par le triplet $(X : Y : Z)$ tel que :
\[ x = \frac{X}{Z^2}, \quad y = \frac{Y}{Z^3} \]
L'équation de la courbe devient homogène de poids $(2, 3, 1)$ :
\[ Y^2 = X^3 + aXZ^4 + bZ^6 \]

\subsection{Analyse Comparative et Complexité}
Pour justifier le choix des coordonnées Jacobiennes, il est essentiel de comparer leur coût opératoire face aux coordonnées affines classiques et aux coordonnées projectives standards (homogènes).

Nous notons :
\begin{itemize}
    \item \textbf{M} : Temps d'une multiplication dans $\mathbb{F}_p$
    \item \textbf{S} : Mise au carré (Squaring) dans $\mathbb{F}_p$ ($1S \approx 0.8M$)
    \item \textbf{I} : Inversion modulaire. C'est l'opération critique, coûtant entre \textbf{20 et 80 M} selon l'architecture.
\end{itemize}

\begin{table}[H]
\centering
\caption{Coût des opérations par système de coordonnées}
\vspace{0.3cm}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Coordonnées} & \textbf{Doublement ($2P$)} & \textbf{Addition ($P+Q$)} & \textbf{Problème Principal} \\ \midrule
Affine $(x, y)$ & $1\mathbf{I} + 2M + 2S$ & $1\mathbf{I} + 2M + 1S$ & Lenteur extrême ($I$) \\
Projectif Std $(X:Y:Z)$ & $7M + 5S$ & $12M + 2S$ & Doublement trop lourd \\
\textbf{Jacobien} $(X:Y:Z)$ & $\mathbf{4M + 4S}$ & $12M + 4S$ & \textbf{Aucun (Optimal)} \\ \bottomrule
\end{tabular}
\end{table}

\newpage

\textbf{Pourquoi les coordonnées Jacobiennes s'imposent-elles ?}
\begin{enumerate}
    \item \textbf{Élimination de l'Inversion :} Contrairement à l'affine, on ne fait aucune inversion $I$ pendant la boucle. On en fait une seule à la toute fin (Conversion finale en coordonées affines).
    \item \textbf{Optimisation du Doublement :} Dans une multiplication scalaire, on fait beaucoup plus de doublements que d'additions.
    \begin{itemize}
        \item Le Projectif Standard coûte $\approx 7M$ par doublement.
        \item Le Jacobien ne coûte que $\approx 4M$ par doublement.
    \end{itemize}
\end{enumerate}

C'est cette différence massive sur le doublement qui rend les coordonnées Jacobiennes indispensables pour la méthode GLV.


\section{La Multiplication Complexe (CM)}
La méthode GLV s'applique aux courbes définies sur un corps fini $\mathbb{F}_p$ dont l'anneau des endomorphismes est isomorphe à un ordre dans un corps quadratique imaginaire $\mathbb{Q}(\sqrt{-D})$.
Concrètement, cela signifie qu'il existe une application non-triviale $\phi : E \to E$ qui est "rapide" à calculer et qui vérifie l'équation caractéristique :
\[ \phi^2 - T\phi + N = 0 \]
Sur un sous-groupe d'ordre premier $n$, $\phi$ agit comme la multiplication par un entier $\lambda$ :
\[ \phi(P) = \lambda P \quad \forall P \in E[n] \]

\begin{remarque}
\textbf{Rentabilité de la méthode :} Le calcul de l'image $\phi(P)$ doit être plus rapide que l'économie réalisée sur la boucle principale.
Dans le cas des endomorphismes simples ($D=3, 4$), ce coût est négligeable (1 multiplication).
Pour les endomorphismes rationnels plus complexes ($D=7, 8$), bien que le calcul de $\phi(P)$ soit plus coûteux, il reste très inférieur au gain massif obtenu par la réduction de moitié du nombre de doublements (environ 128 opérations économisées pour une courbe de 256 bits).
La méthode GLV demeure donc toujours performante.
\end{remarque}

\newpage

% ============================================================
% CHAPITRE 3
% ============================================================
\chapter{Classification des Endomorphismes GLV}

Ce chapitre constitue le cœur théorique de notre analyse. Contrairement aux approches simplifiées, nous détaillons ici les \textbf{quatre familles} de courbes identifiées dans le papier original de GLV, incluant les cas complexes souvent omis.

\section{Cas Simples (Endomorphismes de Degré 1)}
Ces endomorphismes consistent en une simple multiplication des coordonnées par une constante dans $\mathbb{F}_p$. Leur coût est négligeable (1 ou 2 multiplications modulaires).


\subsection{Type 1 : Courbes avec $D=3$ ($j=0$)}
C'est le cas le plus célèbre, utilisé notamment par la courbe \textbf{secp256k1} (Bitcoin).
\begin{itemize}
    \item\textbf{Forme :} $y^2 = x^3 + b$ sur $\mathbb{F}_p$ avec $p \equiv 1 \pmod 3$.
    \item \textbf{Endomorphisme :} $\phi(x, y) = (\beta x, y)$ où $\beta$ est une racine cubique primitive de l'unité ($\beta^3 \equiv 1 \pmod p$).
    \item \textbf{Polynôme caractéristique :} $\lambda^2 + \lambda + 1 \equiv 0 \pmod n$.
    \item \textbf{Calcul de $\lambda$ :} On résout l'équation quadratique pour obtenir $\lambda = \frac{-1 \pm \sqrt{-3}}{2} \pmod n$.
\end{itemize}

\begin{remarque}
Il est crucial de distinguer $\beta$ et $\lambda$ :
\begin{itemize}
    \item $\beta$ est une constante du corps de base $\mathbb{F}_p$ utilisée pour calculer les nouvelles coordonnées.
    \item $\lambda$ est l'entier correspondant dans le groupe scalaire.
\end{itemize}
L'intérêt de la méthode réside dans le fait que l'opération géométrique $(\beta x, y)$ ne coûte qu'une seule multiplication dans $\mathbb{F}_p$, remplaçant ainsi instantanément la multiplication par le grand scalaire $\lambda$.
\end{remarque}

\subsection{Type 2 : Courbes avec $D=4$ ($j=1728$)}
Ce cas concerne une famille spécifique de courbes elliptiques définies sur un corps premier, admettant un endomorphisme efficace.
\begin{itemize}
    \item \textbf{Forme :} $y^2 = x^3 + ax$ sur $\mathbb{F}_p$ avec $p \equiv 1 \pmod 4$.
    \item \textbf{Endomorphisme :} $\phi(x, y) = (-x, \alpha y)$ où $\alpha$ est un élément d'ordre 4 dans $\mathbb{F}_p$ (c'est-à-dire $\alpha^2 \equiv -1 \pmod p$).
    \item \textbf{Polynôme caractéristique :} $\lambda^2 + 1 \equiv 0 \pmod n$.
    \item \textbf{Calcul de $\lambda$ :} La valeur propre correspond à une racine carrée modulaire de $-1$, soit $\lambda \equiv \pm \sqrt{-1} \pmod n$.
\end{itemize}


\newpage


\section{Cas Complexes (Endomorphismes Rationnels)}
Pour certaines courbes, l'endomorphisme $\phi$ ne se réduit pas à une multiplication linéaire. Il s'agit d'une fraction rationnelle. Le coût d'évaluation est plus élevé (plusieurs multiplications dans le corps), mais la méthode reste efficace.

\subsection{Type 3 : Courbes avec $D=7$ ($j= -3375$)}
Ce cas correspond à la multiplication complexe par $\omega = \frac{1 + \sqrt{-7}}{2}$.
\begin{itemize}
    \item \textbf{Forme :} $E : y^2 = x^3 - \frac{3}{4}x^2 - 2x - 1$. 
\end{itemize}
L'endomorphisme est défini par :
\begin{equation}
    \phi(x, y) = \left( \frac{x^2 - \xi}{\xi^2(x - a)}, \frac{y(x^2 - 2ax + \xi)}{\xi^3(x - a)^2} \right)
\end{equation}
Avec les constantes $\xi = \frac{-1 + \sqrt{-7}}{2}$ et $a = \frac{1 + \xi}{4}$.
\begin{itemize}
    \item \textbf{Polynôme caractéristique :} $\lambda^2 - \lambda + 2 \equiv 0 \pmod n$.
\end{itemize}

\subsection{Type 4 : Courbes avec $D=8$ ($j=8000$)}
Soit $p > 3 $ un nombre premier tel que $-2$ soit un carré parfait dans $\mathbb{F}_p$.

\begin{itemize}
    \item \textbf{Forme :} $E : y^2 = 4x^3 - 30x - 28 \pmod p$ 
\end{itemize}

L'endomorphisme est défini par :
\begin{equation}
    \phi(x, y) = \left( \frac{-2x^2 + 4x + 9}{4(x+2)}, \quad \frac{-2x^2 + 8x - 1}{4\sqrt{-2}(x+2)^2} \cdot y \right)
\end{equation}
Note : Cette formule nécessite que $x \neq -2$. Le terme $\sqrt{-2}$ désigne une racine carrée de $-2$ fixée dans $\mathbb{F}_p$.

\begin{itemize}
    \item \textbf{Polynôme caractéristique :} $\lambda^2 + 2 \equiv 0 \pmod n$.
    \item \textbf{Calcul de $\lambda$ :} $\lambda \equiv \pm \sqrt{-2} \pmod n$.
\end{itemize}

\begin{remarque}
L'implémentation de ces deux derniers cas nécessite une arithmétique de corps très optimisée, car l'évaluation de $\phi$ coûte environ 10 multiplications. Cependant, le gain sur la décomposition scalaire compense largement ce surcoût.
\end{remarque}

\begin{remarque}
\textbf{Condition d'existence sur le corps de base :}
L'appartenance d'une courbe à l'une de ces familles (identifiée par son invariant $j$) garantit l'existence théorique de l'endomorphisme $\phi$.
Cependant, pour que la méthode GLV soit applicable en pratique, l'endomorphisme doit être défini sur $\mathbb{F}_p$. Cela impose une condition de congruence sur le nombre premier $p$ (par exemple $p \equiv 1 \pmod 4$ pour le type $D=4$), assurant que les constantes nécessaires à $\phi$ existent bien dans le corps de base.
\end{remarque}

\begin{remarque}
    Dans notre programme, nous avons seulement implémenté la méthode GLV sur le type 1, 2 et 3, avec les valeurs officielles de secp256k1 pour le type 1, et des valeurs générés aléatoirement vérifiant les conditions pour le type 2 et 3.
\end{remarque}

\newpage

% ============================================================
% CHAPITRE 4
% ============================================================
\chapter{Algorithmes de Décomposition et Réseaux}

Une fois le $\lambda$ identifié pour notre courbe, le défi est algorithmique : comment trouver $k_1, k_2$ petits tels que $k \equiv k_1 + k_2 \lambda \pmod n$ ?

\section{Formulation en Problème de Réseau (Lattice)}
Considérons l'homomorphisme $f : \mathbb{Z}^2 \to \mathbb{Z}_n$ défini par $f(u, v) = u + v\lambda \pmod n$.
Le noyau de cet homomorphisme est un réseau $\mathcal{L}$ de dimension 2 :
\[ \mathcal{L} = \{ (u, v) \in \mathbb{Z}^2 \mid u + v\lambda \equiv 0 \pmod n \} \]
Le problème de la décomposition revient à trouver un vecteur $v \in \mathcal{L}$ qui soit le plus proche possible du vecteur cible $(k, 0)$.
Si nous trouvons un tel $v$, alors le vecteur différence $u = (k, 0) - v $ sera court (sa norme euclidienne est petite), et par construction, si on note $u=(k_1, k_2),\, v= (v_1, v_2)$, on a :
\[ k_1 + k_2\lambda \equiv (k - v_1) + (-v_2)\lambda \equiv k - (v_1 + v_2\lambda) \equiv k \pmod n \]

\section{Étape 1 : Génération de la Base (Euclide Étendu)}
Nous devons d'abord trouver une base de vecteurs courts $(v_1, v_2)$ pour le réseau $\mathcal{L}$.
L'algorithme d'Euclide Étendu (EEA) appliqué à $n$ et $\lambda$ génère une suite de restes $r_i$ décroissants. Nous arrêtons l'algorithme lorsque le reste $r_i$ devient inférieur à $\sqrt{n}$.

\begin{algorithm}[H]
\SetAlgoLined
\KwData{Ordre $n$, Valeur propre $\lambda$}
\KwResult{Base réduite $v_1, v_2$}
$(r_0, t_0) \gets (n, 0)$\;
$(r_1, t_1) \gets (\lambda, 1)$\;
$i \gets 1$\;
\While{$r_i \ge \sqrt{n}$}{
    $q_i \gets \lfloor r_{i-1} / r_i \rfloor$\;
    $r_{i+1} \gets r_{i-1} - q_i r_i$\;
    $t_{i+1} \gets t_{i-1} - q_i t_i$\;
    $i \gets i + 1$\;
}
$m \gets i$\;
$v_1 \gets (r_m, -t_m)$\;
$v_2 \gets (r_{m-1}, -t_{m-1})$\;
\caption{Précalcul de la Base GLV via EEA}
\end{algorithm}
Cette base est calculée une seule fois lors de l'initialisation des paramètres de la courbe.

\subsection{Justification de la terminaison}

À chaque itération de l'algorithme, les restes satisfont :
\[
r_{i+1} = r_{i-1} - q_i r_i, \quad 0 \le r_{i+1} < r_i.
\]

Ainsi, la suite \((r_i)_{i\ge0}\) est strictement décroissante et composée de nombres entiers non négatifs.  

\textbf{Observation importante :} si $\gcd(n, \lambda) = d$, alors le dernier reste non nul de l'EEA vaut $d$. Dans la pratique GLV, on a toujours $\gcd(n, \lambda) = 1$, et la suite peut donc toujours descendre jusqu'à un reste $r_m < \sqrt{n}$.  

Par conséquent, la boucle `while` terminera toujours.

\subsection{Justification de la correction}

\paragraph{1. Appartenance au réseau $\mathcal{L}$ :} 
Par construction, la suite $(r_i, t_i)$ est issue de l'algorithme d'Euclide Étendu appliqué à $(n, \lambda)$, donc
\[
r_i = n s_i + \lambda t_i \quad \text{pour certains } s_i \in \mathbb{Z}.
\]
Ainsi
\[
r_i - t_i \lambda = n s_i \equiv 0 \pmod n \implies (r_i, -t_i) \in \mathcal{L}.
\]

\paragraph{2. Vecteurs courts :} 
À chaque itération, on a $r_{i+1} = r_{i-1} - q_i r_i$ avec $0 \le r_{i+1} < r_i$. On s'arrête dès que $r_m < \sqrt{n}$.  

- Pour le vecteur $v_1 = (r_m, -t_m)$, sa norme euclidienne est
\[
\|v_1\| = \sqrt{r_m^2 + t_m^2} \le \sqrt{r_m^2 + r_m^2} = r_m \sqrt{2} < \sqrt{2 n},
\]
car $|t_m| < r_m$ (propriété standard de l'EEA : les coefficients $t_i$ satisfont $|t_i| < r_{i-1}/r_i$).  

- Pour le vecteur $v_2 = (r_{m-1}, -t_{m-1})$, on a $r_{m-1} > r_m$ mais $r_{m-1} < n$, donc la norme reste de l’ordre $O(\sqrt{n})$, même si l'argument heuristique.  

Ainsi, les deux vecteurs sont courts pour la décomposition GLV.

\paragraph{3. Indépendance linéaire :} Par construction de l'EEA, $(r_m, r_{m-1})$ et $(t_m, t_{m-1})$ satisfont le relation de Bézout
\[
r_{m-1} t_m - r_m t_{m-1} = \pm n \neq 0.
\]  
Ainsi le déterminant de la matrice
\[
\begin{pmatrix} r_m & r_{m-1} \\ -t_m & -t_{m-1} \end{pmatrix} 
\]
est non nul.  Les vecteurs sont donc linéairement indépendants sur $\mathbb{Z}$ et forment une base du réseau $\mathcal{L}$.

\paragraph{Conclusion :} 
L’algorithme produit deux vecteurs $(v_1, v_2)$ qui :
\begin{itemize}
    \item appartiennent à $\mathcal{L}$,
    \item sont courts (norme $O(\sqrt{n})$),
    \item et sont linéairement indépendants.
\end{itemize}
Ils forment donc une base réduite appropriée pour la méthode GLV.

\section{Étape 2 : Décomposition de Babai (Rounding)}
Pour un scalaire $k$ donné à l'exécution, nous résolvons le CVP (Closest Vector Problem) approximatif dans le plan.
On cherche $v = c_1 v_1 + c_2 v_2 \approx (k, 0)$.

\subsection{Algorithme}
1. Résolution dans $\mathbb{Q}$ : On résout le système linéaire $(k, 0) = c_1 v_1 + c_2 v_2$. Grâce à la règle de Cramer :
\[ c_1 = \frac{k \times v_{2,y}}{\det(v_1, v_2)}, \quad c_2 = \frac{k \times (-v_{1,y})}{\det(v_1, v_2)} \]
2. Arrondi : On arrondit les coefficients rationnels à l'entier le plus proche :
\[ b_1 = \lfloor c_1 \rceil, \quad b_2 = \lfloor c_2 \rceil \]
3. Réduction : Le vecteur court est obtenu par soustraction :
\[ (k_1, k_2) = (k, 0) - b_1 v_1 - b_2 v_2 \]

\begin{theoreme}[Bornes de Babai]
Les scalaires $k_1, k_2$ obtenus par cette méthode satisfont $|k_1|, |k_2| < \epsilon \sqrt{n}$ avec $\epsilon$ une petite constante dépendant de la géométrie du réseau (typiquement $\sqrt{1 + |\lambda|^2}$).
\end{theoreme}

\newpage

% ============================================================
% CHAPITRE 5
% ============================================================
\chapter{Architecture logicielle et Optimisations}

L'implémentation de la méthode GLV a été réalisée en langage C, en s'appuyant sur la bibliothèque \textbf{GMP} (GNU Multiple Precision Arithmetic Library) pour la gestion efficace des grands entiers. Ce chapitre détaille l'organisation modulaire du code ainsi que les choix algorithmiques critiques effectués pour maximiser la performance et la précision des calculs.

\section{Architecture Modulaire}

Le projet est structuré selon une logique de couches, séparant l'arithmétique de bas niveau, la gestion algébrique des courbes et la logique de haut niveau propre à l'algorithme GLV. Cette modularité facilite la maintenance et les tests unitaires.



\begin{figure}[ht]
\centering
\resizebox{\textwidth}{!}{
\begin{tikzpicture}[
    box/.style={
        draw,
        rectangle,
        rounded corners,
        minimum width=3.4cm,
        minimum height=0.9cm,
        align=center,
        font=\small
    },
    >=Latex,
    node distance=1.4cm and 1.6cm
]

% Top
\node[box] (gmp) {\texttt{gmp.h}};

% Level 1
\node[box, below=of gmp] (struct) {\texttt{EC\_struct.h}};

% Level 2
\node[box, left=of struct] (addproj) {\texttt{EC\_add\_proj.h}};
\node[box, below=of struct] (precomp) {\texttt{precompute\_table.h}};
\node[box, below right=of struct] (shortv) {\texttt{short\_vectors.h}};
\node[box, right=3.8cm of struct] (affine) {\texttt{EC\_add\_affine.h}};
\node[box, right =of shortv] (sqaff) {\texttt{EC\_square\_and\_multiply\_affine.h}};

% Level 3
\node[box, below left=of addproj] (sqproj) {\texttt{EC\_square\_and\_multiply\_proj.h}};
\node[box, below=of precomp] (double) {\texttt{double\_scalar\_multiplication.h}};
\node[box, right =of double] (gldecomp) {\texttt{glv\_decompose.h}};
\node[box, left=of double] (endo) {\texttt{EC\_endo\_phi\_GLV.h}};

% Level 4
\node[box, left=of endo] (quad) {\texttt{quadratic\_solver.h}};
\node[box, below =of endo] (glvcurves) {\texttt{glv\_curves.h}};
\node[box, below=of double] (ecglv) {\texttt{EC\_glv.h}};

% Bottom
\node[box, below left=of glvcurves] (accel) {\texttt{glv\_acceleration.h}};
\node[box, right = 4.8cm of accel] (dh) {\texttt{EC\_DH.h}};
\node[box, right = 4.8cm of dh] (demo) {\texttt{EC\_GLV\_demo.h}};
\node[box, below=of dh] (main) {\texttt{main.c}};

% Connections
\draw[->] (gmp) -- (struct);

\draw[->] (struct) -- (addproj);
\draw[->] (struct) -- (precomp);
\draw[->] (struct) -- (shortv);
\draw[->] (struct) -- (affine);
\draw[->] (struct) -- (endo);

\draw[->] (affine) -- (sqaff);

\draw[->] (addproj) -- (sqproj);
\draw[->] (addproj) -- (double);
\draw[->] (precomp) -- (double);
\draw[->] (shortv) -- (gldecomp);

\draw[->] (gldecomp) -- (glvcurves)
\draw[->] (gldecomp) -- (ecglv)

\draw[->] (endo) -- (ecglv);
\draw[->] (endo) -- (quad);
\draw[->] (double) -- (ecglv);

\draw[->] (sqproj) -- (quad);
\draw[->] (quad) -- (glvcurves);

\draw[->] (glvcurves) -- (accel);
\draw[->] (glvcurves) -- (dh);
\draw[->] (glvcurves) -- (demo);
\draw[->] (ecglv) -- (dh);
\draw[->] (ecglv) -- (demo);
\draw[->] (ecglv) -- (accel);

\draw[->] (dh) -- (main);
\draw[->] (accel) -- (main);
\draw[->] (demo) -- (main);

\end{tikzpicture};
}
\caption{Dépendances des fichiers du projet}
\end{figure}

\begin{figure}[H]
\centering
\textbf{Architecture du Projet en Couches}
\vspace{0.3cm}

% --- Couche 1 ---
\fbox{
    \parbox{12cm}{\centering
    \textbf{1. Interface et Benchmarks} \\
    \small \textit{Point d'entrée, mesures de temps, tests, et générations de clés Diffie-Hellmann} \\
    \texttt{main.c, gen\_const\_*.sage.py, glv\_acceleration.c, EC\_DH.c, EC\_GLV\_demo.c}}
}

% Jonction 1
$\downarrow$

% --- Couche 2 ---
\fbox{
    \parbox{12cm}{\centering
    \textbf{2. Logique de Contrôle GLV} \\
    \small \textit{Orchestration, Décomposition (Babai) et Réduction} \\
    \texttt{EC\_GLV.c, glv\_decompose.c, short\_vectors.c, glv\_curves.c}}
}

% Jonction 2
$\downarrow$

% --- Couche 3 ---
\fbox{
    \parbox{12cm}{\centering
    \textbf{3. Moteur de Multiplication} \\
    \small \textit{Calcul simultané $kP + lQ$ (Shamir w-ary)} \\
    \texttt{double\_scalar\_multiplication.c, precompute\_table.c}}
}

% Jonction 3
$\downarrow$

% --- Couche 4 ---
\fbox{
    \parbox{12cm}{\centering
    \textbf{4. Couche Algébrique} \\
    \small \textit{Paramètres courbes \& Endomorphismes ($\phi$)} \\
    \texttt{glv\_curves.c, EC\_endo\_phi\_GLV.c, quadratic\_solver.c}}
}

% Jonction 4
$\downarrow$

% --- Couche 5 ---
\fbox{
    \parbox{12cm}{\centering
    \textbf{5. Noyau Arithmétique (GMP)} \\
    \small \textit{Opérations de base (Add/Double) Affines \& Projectives} \\
    \texttt{EC\_add\_proj.c, EC\_square\_and\_multiply\_proj.c}}
}

% Jonction 5
$\downarrow$

% --- Couche 6 ---
\fbox{
    \parbox{12cm}{\centering
    \textbf{6. Structures informatiques (courbes, points) (GMP)} \\
    \small \textit{Allocations, Désallocations, conversions Affines \& Projectives, Tests d'égalités} \\
    \texttt{EC\_struct.c}}
}

\caption{Organisation hiérarchique détaillée des fichiers sources}
\end{figure}



\section{Optimisations Algorithmiques Implémentées}

Au-delà de l'application théorique de la méthode GLV, quatre optimisations majeures ont été intégrées pour réduire drastiquement le temps d'exécution.

\subsection{Coordonnées Projectives Jacobiennes}
L'inversion modulaire est l'opération la plus coûteuse dans un corps fini $\mathbb{F}_p$ (coûtant environ 80 fois plus cher qu'une multiplication). Dans une multiplication scalaire classique, chaque addition de points nécessite une inversion pour calculer la pente de la droite ($\lambda$).

Pour éliminer ce frein, nous travaillons en \textbf{coordonnées Jacobiennes} $(X : Y : Z)$. Un point projectif correspond au point affine :
\begin{equation}
    x = \frac{X}{Z^2}, \quad y = \frac{Y}{Z^3}
\end{equation}
Les formules d'addition et de doublement implémentées dans \texttt{EC\_add\_proj.c} ne requièrent aucune inversion. Une unique inversion est effectuée à la toute fin du calcul (dans \texttt{proj\_to\_affine}) pour revenir aux coordonnées cartésiennes.

\subsection{Décomposition par Arrondi (Babai's Rounding)}
La décomposition du scalaire $k$ en deux mini-scalaires $k_1, k_2$ repose sur la résolution du problème du vecteur le plus court (CVP) dans un réseau de dimension 2.

Plutôt qu'une recherche exhaustive, nous avons implémenté l'algorithme de l'arrondi au plus proche (Babai's Nearest Plane) dans le fichier \texttt{glv\_decompose.c}.
L'algorithme calcule une approximation flottante de la solution dans la base du réseau, puis arrondit le résultat à l'entier le plus proche via la fonction \texttt{mpz\_round\_div} :
\begin{equation}
    (b_1, b_2) = \left\lfloor \frac{k \cdot v}{\det(L)} \right\rceil
\end{equation}
Cette approche garantit une complexité constante $O(1)$, rendant l'étape de décomposition négligeable par rapport au gain obtenu sur la multiplication.


\subsection{Multiplication Simultanée avec Fenêtrage (Interleaving w-ary)}
L'optimisation la plus avancée du projet se trouve dans \texttt{double\_scalar\_multiplication.c}.
Pour calculer la combinaison linéaire $k_1P + k_2Q$, nous n'effectuons pas deux multiplications séparées. Nous utilisons une méthode d'entrelacement (Interleaving) combinée à du \textbf{fenêtrage (Windowing)} de taille $w$. Le paramètre $w$ doit être choisi judicieusement, plus il est grand, moins la boucle principale aura d'itérations, mais plus le temps de précalcul sera long (empiriquement, $w=2$ donne la meilleur accélération).

\begin{enumerate}
    \item \textbf{Précalcul :} Une table $T$ est générée (dans \texttt{precompute\_table.c}) contenant les valeurs pré-calculées $uP + vQ$ pour toutes les combinaisons possibles de fenêtres $0 \le u, v < 2^w$.
    \item \textbf{Boucle principale :} On parcourt les scalaires $k_1$ et $k_2$ par paquets de $w$ bits simultanément.
    \item \textbf{Accumulation :} À chaque itération, on effectue $w$ doublements du point résultat, puis une seule addition avec la valeur pré-calculée correspondante tirée de la table $T$.
\end{enumerate}

Cette technique, souvent appelée \textit{Straus-Shamir optimization}, réduit considérablement le nombre d'additions de points nécessaires par rapport à la méthode binaire simple.

\subsection{Endomorphismes Efficaces}
Le calcul de l'image $\phi(P)$ (le point $Q$) est implémenté nativement pour plusieurs types de courbes via \texttt{EC\_endo\_phi\_GLV.c}.
Pour les courbes $j=0$ (Type 1) et $j=1728$ (Type 2), l'opération se résume à une simple multiplication modulaire d'une coordonnée par une racine de l'unité $\beta$.
Cette opération étant quasi-instantanée (complexité équivalente à une multiplication dans $\mathbb{F}_p$), elle valide l'hypothèse fondamentale de GLV : le coût d'obtention du deuxième point $Q$ est « gratuit ».

\section{Gestion de la Mémoire et Robustesse}
L'utilisation de la bibliothèque GMP impose une gestion rigoureuse de la mémoire dynamique.
\begin{itemize}
    \item \textbf{Allocation/Libération :} Toutes les fonctions arithmétiques utilisent des variables temporaires initialisées via \texttt{mpz\_inits} et systématiquement libérées avec \texttt{mpz\_clears} pour prévenir les fuites de mémoire.
    \item \textbf{Reproductibilité :} Les benchmarks de performance (dans \texttt{glv\_acceleration.c}) utilisent un générateur aléatoire \texttt{gmp\_randstate\_t} initialisé avec l'entropie système (\texttt{time(NULL)}), assurant que les tests couvrent un espace de scalaires varié et réaliste.
\end{itemize}

\subsection{Rôle des scripts de pré-calcul (SageMath)}
L'utilisation conjointe de \textbf{SageMath} et du \textbf{C} répond à une séparation stricte des responsabilités. Le langage C, bien que très performant pour l'arithmétique, ne dispose pas nativement d'algorithmes de théorie des nombres avancés (comme l'algorithme de Schoof-Elkies-Atkin pour compter les points d'une courbe).

Les fichiers \texttt{gen\_const\_*.sage} agissent donc comme un oracle mathématique en amont de la compilation :
\begin{itemize}
    \item Ils génèrent des nombres premiers $p$ et des courbes elliptiques satisfaisant les conditions de sécurité cryptographique.
    \item Ils vérifient l'existence de l'endomorphisme $\phi$ et calculent les constantes critiques $\beta$ (racine de l'unité) et $\lambda$ (valeur propre).
    \item Ils exportent ces paramètres sous forme de chaînes hexadécimales, qui sont ensuite "codées en dur" dans le fichier C \texttt{glv\_curves.c}.
\end{itemize}
Cette approche permet de décharger le programme principal de la complexité de l'initialisation pour se concentrer uniquement sur la performance de la multiplication scalaire.


%%\subsection{Comparaison avec la JSF}
%%Une alternative courante à la technique de \textit{Straus-Shamir} est la \textit{Joint Sparse Form} (JSF), qui recode les scalaires pour minimiser le nombre de colonnes non nulles. Bien que la JSF soit très efficace en mémoire (nécessitant peu de précalculs), notre approche par fenêtrage offre un compromis différent : elle utilise plus de mémoire pour stocker la table $T$, mais réduit le nombre d'opérations d'addition en traitant plusieurs bits à la fois, ce qui est particulièrement adapté aux architectures modernes disposant de cache suffisant.

\newpage

% ============================================================
\chapter{Analyse des Résultats}

\section{Modèle de Performance Théorique}

Comme établi dans l'article fondateur de Gallant, Lambert et Vanstone (2001), l'apport fondamental de la méthode GLV réside dans la réduction de la longueur de la boucle principale de \textbf{50\%}.
Au lieu de parcourir $n$ bits (taille du corps), nous parcourons $\approx n/2$ bits (taille des mini-scalaires $k_1, k_2$).

Comparons le coût théorique pour un scalaire de 256 bits ($n=256$) :
\begin{itemize}
    \item $D$ : Coût d'un doublement.
    \item $A$ : Coût d'une addition (mixte).
\end{itemize}

\begin{table}[H]
\centering
\caption{Comparaison Théorique (Réduction de 50\%)}
\vspace{0.3cm}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Méthode} & \textbf{Boucle (Doublements)} & \textbf{Additions (Moy.)} & \textbf{Coût Total ($D$)} \\ \midrule
Classique (Double-and-Add) & 256 ($n$) & 128 & $\approx 448 D$ \\
GLV (Shamir + Fenêtrage) & \textbf{128 ($n/2$)} & $\approx 64$ & $\approx \mathbf{224 D}$ \\ \bottomrule
\end{tabular}
\end{table}

\paragraph{Analyse :}
La complexité est divisée par deux :
\[ \text{Coût}_{GLV} \approx 0.5 \times \text{Coût}_{Classique} \]
Cette réduction de 50\% des opérations arithmétiques implique un facteur d'accélération théorique (Speedup) de :
\[ \text{Speedup Théorique} = \frac{1}{0.5} = \mathbf{2.0 \times} \]

\section{Résultats Expérimentaux}

\subsection{Protocole de Test}
Les mesures ont été réalisées via le fichier \texttt{glv\_acceleration.c} sur une machine standard. Le protocole est le suivant :
\begin{itemize}
    \item \textbf{Échantillon :} 1000 multiplications scalaires par série de test.
    \item \textbf{Scalaires :} Générés aléatoirement (\texttt{mpz\_urandomm}) sur 256 bits à chaque itération.
    \item \textbf{Graine :} Initialisée via \texttt{time(NULL)} pour assurer la variabilité des tests.
    \item \textbf{Comparaison :} Mesure du temps CPU (\texttt{clock\_t}) entre l'implémentation classique (\texttt{ec\_scalar\_mul\_proj}) et l'implémentation GLV (\texttt{ec\_scal\_mul\_glv}).
\end{itemize}

\subsection{Mesures Recueillies}
Nous avons effectué quatre campagnes de tests consécutives. Les résultats sont consignés ci-dessous :

\begin{table}[H]
\centering
\caption{Benchmarks : Temps pour 1000 multiplications (sec)}
\vspace{0.3cm}
\begin{tabular}{@{}ccccc@{}}
\toprule
 \textbf{Taille de fenetrage ($w$)} & \textbf{Type} &  \textbf{Classique (s)} & \textbf{GLV (s)} & \textbf{Gain (Speedup)} \\ \midrule
 1 & 1 & 0.467192 & 0.296538 & \textbf{1.58 x} \\
 1 & 2 & 0.511694 & 0.321901 & \textbf{1.59 x} \\
 1 & 3 & 0.529827 & 0.325675 & \textbf{1.63 x} \\
 \midrule
 2 & 1 & 0.485404 & 0.275656 & \textbf{1.76 x} \\
 2 & 2 & 0.496635 & 0.282760 & \textbf{1.76 x} \\
 2 & 3 & 0.525960 & 0.297335 & \textbf{1.77 x} \\
 \midrule
 3 & 1 & 0.457346 & 0.324382 & \textbf{1.41 x} \\
 3 & 2 & 0.488046 & 0.339406 & \textbf{1.44 x} \\
 3 & 3 & 0.540056 & 0.364112 & \textbf{1.48 x} \\
 \midrule
 4 & 1 & 0.496288 & 0.747927 & \textbf{0.66 x} \\
 4 & 2 & 0.500335 & 0.706349 & \textbf{0.71 x} \\
 4 & 3 & 0.542002 & 0.728592 & \textbf{0.74 x} \\
 
\bottomrule
\end{tabular}
\end{table}

Nous observons une accélération moyenne stable entre les différents types, la vraie différence vient du choix de $w$. Le temps de précalcul en $\mathcal{O}(2^{2w})$, car on doit calculer naïvement $iP+jQ$, pour $0\leq i,j<2^w$. Ce temps de précalcul explose donc rapidement, ce qui explique pour le gain maximal est atteint pour $w=2$, et que pour $w>4$, la méthode GLV est plus lente que l'exponentiation rapide. Nous avons d'ailleurs mis un failsafe dans la fonction \texttt{ec\_double\_scalar\_multiplication}.

Le speedup maximal atteint est $\approx1.76$, ce qui signifie que la méthode GLV est 76\% plus rapide que l'exponentiation rapide. 

\subsection{Interprétation de la Performance}
Le gain mesuré (1.76x) est excellent, bien que légèrement inférieur au facteur théorique (2.0x). Cette différence s'explique par les coûts fixes inhérents à notre architecture logicielle, visibles dans \texttt{EC\_GLV.c} :

\begin{enumerate}
    \item \textbf{Coût de conversion de coordonnées :} Pour appliquer l'endomorphisme $\phi(x,y) = (\beta x, y)$, nous convertissons le point P de projectif vers affine. Cette opération (\texttt{proj\_to\_affine}) implique une \textbf{inversion modulaire} (\texttt{mpz\_invert}), qui est une opération très coûteuse.
    \item \textbf{Overhead de la Décomposition :} L'algorithme de Babai (\texttt{glv\_nearest\_vector}) nécessite plusieurs multiplications de grands entiers avant même que la multiplication scalaire ne commence.
    \item \textbf{Gestion Mémoire GMP :} Contrairement à une implémentation sur carte à puce statique, l'utilisation de GMP impose des allocations dynamiques (\texttt{malloc}) et des initialisations (\texttt{mpz\_init}) à chaque appel de fonction, ce qui pèse sur le temps d'exécution global.
\end{enumerate}

Malgré ces overheads, le gain reste massif, validant l'efficacité de la réduction de la boucle principale de 256 à 128 itérations.

\section{Conclusion Générale}

Ce projet a permis d'explorer et d'implémenter la méthode de Gallant-Lambert-Vanstone (GLV) sur une courbe elliptique de type secp256k1 et sur d'autres types de courbes plus ou moins complexes. En structurant le code en couches modulaires, nous avons pu isoler la complexité mathématique (réduction de réseau, endomorphismes) pour nous concentrer sur l'optimisation du moteur arithmétique.

Les résultats expérimentaux sont très satisfaisants :
\begin{itemize}
    \item Nous avons mesuré une accélération moyenne de \textbf{1.76x} (gain de 76\%) par rapport à la méthode classique.
    \item Ce résultat dépasse les estimations prudentes des auteurs originaux (Gallant, Lambert, Vanstone, 2001) qui annonçaient une accélération d'environ 50\% (\textit{"roughly 50\% faster"}, soit un facteur 1.5x).
\end{itemize}

Cette performance supérieure aux prédictions s'explique par la synergie entre la décomposition GLV et notre implémentation de la méthode de \textbf{Shamir avec fenêtrage} ($w=2$). Là où la méthode GLV divise par deux la longueur de la boucle, le fenêtrage réduit encore le nombre d'additions intermédiaires.

Nous avons ainsi démontré que sur une architecture moderne, le surcoût des pré-calculs (Babai, tables) est largement compensé par le gain sur la multiplication scalaire. Pour aller plus loin, l'utilisation de la \textit{Joint Sparse Form} (JSF) pourrait être envisagée pour réduire l'empreinte mémoire, ou une implémentation en assembleur pour se rapprocher encore davantage de la limite théorique d'un facteur 2.0.

% --- BIBLIOGRAPHIE ---

\vspace{1cm}
\hrule
\vspace{1cm}

{
\let\clearpage\relax 
\let\chapter\section 

\begin{thebibliography}{9}

    % 1. LE PAPIER PRINCIPAL (GLV) 
    \bibitem{glv2001}
    R. P. Gallant, R. J. Lambert, and S. A. Vanstone,
    \textit{``Faster Point Multiplication on Elliptic Curves with Efficient Endomorphisms''},
    in Advances in Cryptology — CRYPTO 2001, Springer, pp. 190–200, 2001.
    \newline
    \small \texttt{https://www.iacr.org/archive/crypto2001/21390189.pdf}.

    % 2. BABAI (Pour l'algo de décomposition / CVP)
    \bibitem{babai86}
    L. Babai,
    \textit{``On Lovász' lattice reduction and the nearest lattice point problem''},
    Combinatorica, vol. 6, no. 1, pp. 1–13, 1986.

    % 3. STRAUSS-SHAMIR (La bible de la crypto qui explique l'algo)
    \bibitem{hac}
    A. J. Menezes, P. C. van Oorschot, and S. A. Vanstone,
    \textit{``Handbook of Applied Cryptography''},
    CRC Press, 1996. (Section 14.6.3 : Simultaneous multiple exponentiation, Alg. 14.88).

    % 4. Notre GITHUB
    \bibitem{github}
    Dépôt GitHub du Projet,
    \textit{Code source complet et scripts SageMath},
    \newline
    \texttt{https://github.com/alexandreroullet3-dotcom/Projet-C-GLV}

\end{thebibliography}
}
\end{document}